
                         +-----------------+
                         |      CS 406     |
                         |   PROJECT ONE   |
                         | DESIGN DOCUMENT |
                         +-----------------+

---- GROUP ----

Angela Shi <shiy@lafayette.edu>
James Nigro <nigroj@lafayette.edu>
Ingrid Rumbaugh <rumbaugi@lafayette.edu>
Kerry Stranick <stranick@lafayette.edu>

---- PRELIMINARIES ----
Currently, this is an unfinished version of our design document of priority schedling.


                              PRIORITY SCHEDULING
                                     ====

---- DATA STRUCTURES ----

>> Copy here the declaration of each new or changed `struct' or `struct'
>> member, global or static variable, `typedef', or enumeration.
>> Identify the purpose of each in 25 words or less.

Added to struct thread:

  /* Members for implementing priority scheduling */
  struct list donation_list;           /* Contains threads that are waiting on the lock that the 
                                          current thread owns. */
  struct list_elem donation_list_elem; /* Contains the the list elements of the threads that are 
                                          waiting on the lock. */
  struct lock* wait_on_lock;           /* Denotes which lock the waiting thread is currently
                                          waiting on. */
  int old_priority;                    /* Used for saving and restoring the priority of the
                                          donating thread. */

---- ALGORITHMS ----

>> Briefly describe your implementation of priority scheduling and how it
>> interacts with thread termination.

A new thread (call it T1)'s priority is set when it is created in the thread_create() call.
Once T1's priority is set, it temporarily becomes the currently running thread by making
the currently running thread (call it T2) yield. T2 is placed at the head of a waiting list.
T1's priority is checked against the priority of T2; if T1's priority is lower than T2's
priority, it yields and T2 becomes the currently running thread again. Otherwise, T2
remains yielded and T1 continues its execution.

Lock acquisition is also handled within our implementation of priority scheduling. When a
thread tries to acquire a lock, it first checks if the lock is already held. If it is, the
thread is placed into a list of threads that are waiting on the lock in question; if not,
the sema_down() function is called. In sema_down(), we donate the current thread's priority
to the lock holder's priority if the former's priority is higher than the latter's. We
then block the current thread until the semaphore is available again, at which point it
will get the lock and resume its execution.

When a lock is released, all the threads that are waiting for it are removed from the
donation list of the thread that held the lock. Then, the priority of the currently
running thread is restored to its pre-donation priority. Lastly, we re-sort the list
of waiters on the given semaphore and wake up the one with the highest priority. Since
context switches are blocked during this process, we check again if the currently
running thread needs to be blocked after we wake up the thread at the top of the
waiting list.

---- SYNCHRONIZATION ----

>> An operating system kernel is a complex, multithreaded program,
>> in which synchronizing multiple threads can be difficult. How
>> did you choose to synchronize priority scheduling?

The threads are synchronized using semaphores and locks, as well as pausing context
switches and interrupts. Pausing context switches and interrupts allows us to
determine the priorities of the various threads before checking which thread becomes
active, thus avoiding any possibility of low priority becoming the active thread.
Our waiting lists, which are held by each individual thread as opposed to being part
of a global structure, also help with keeping track of which threads are waiting on
which locks without the possibility of being tampered with.

---- RATIONALE ----

>> Critique your design, pointing out advantages and disadvantages in
>> your design choices.

One of our advantages in the design is that all our lists are ordered so that it is
easy to get the highest threads which are at the front of the lists. We also kept
changes in data structures within one structure (struct thread) and one file (thread.c).
A disadvantage we have in our design code is our programming practice. The naming of 
some of our functions and variables are not very consistent and therefore it is sometimes
confusing to use them, especially across different files (thread.c and synch.c).

We also could have edited the data structures (locks, semaphores, conditional variables)
in synch.c and the algorithm would look very different. Although this different design
does not necessarily ensure that it is more efficient than our current design, we did not
have time to give more consideration on the choice of our design.
